# LLM 의 b 단위 개념정리 

---

>

## `b`란 무엇인가?

- `b`는 billion(10억)을 의미하며, LLM의 “파라미터(Parameter) 개수”를 나타낸다.

> 파라미터 = 모델이 학습을 통해 얻은 가중치(지식 + 규칙)

------

## `b` 숫자가 의미하는 것

| 표기 | 의미              |
| ---- | ----------------- |
| 7b   | 70억 개 파라미터  |
| 14b  | 140억 개 파라미터 |
| 30b  | 300억 개 파라미터 |
| 70b  | 700억 개 파라미터 |

## Ollama 기준 “대략적인 요구 스펙”

> **양자화(q4, q8 등) 기준 + 대략값**

| 모델 크기 | RAM 최소 | 체감         |
| --------- | -------- | ------------ |
| 7b        | 8~10GB   | 빠름         |
| 14b       | 16~24GB  | 실사용 가능  |
| 30b       | 32~48GB  | 매우 느림    |
| 70b       | 64GB+    | 서버급       |
| 235b      | x        | 개인 PC 불가 |

------

## 파라미터 수가 커질수록

##### 좋아지는 점

- 문맥 이해력
- 추론(Reasoning) 능력
- 복잡한 규칙 처리
- 모호한 입력 대응력

##### 나빠지는 점

- 메모리 사용량 증가
- 응답 속도 저하
- 하드웨어 요구사항 증가

------

## 핵심 요약

- `b`는 **모델의 크기(두뇌 용량)** 를 뜻한다
- 클수록 똑똑하지만 **무조건 좋은 건 아님**
- 로컬 Ollama 환경에서는 **7b~14b가 현실적인 선택**